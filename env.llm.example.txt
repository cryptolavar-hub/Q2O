# Q2O LLM Integration - Production Configuration
# Copy this to .env (or add these to your existing .env)

# ============================================================================
# LLM FEATURE FLAGS
# ============================================================================
Q2O_USE_LLM=true                          # Enable LLM integration (true/false)
Q2O_LLM_MODE=hybrid                       # hybrid | llm_first | template_only

# ============================================================================
# API KEYS (Get from respective provider dashboards)
# ============================================================================

# Gemini API (Primary - Recommended)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIzaSy_REPLACE_WITH_YOUR_ACTUAL_KEY_HERE

# OpenAI API (Fallback - Required)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-REPLACE_WITH_YOUR_ACTUAL_KEY_HERE

# Anthropic Claude API (Tertiary - Optional)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-REPLACE_WITH_YOUR_ACTUAL_KEY_HERE

# ============================================================================
# PROVIDER CONFIGURATION
# ============================================================================

# System-Level Defaults (can be overridden per project/agent)
Q2O_LLM_PRIMARY=gemini                    # gemini | openai | anthropic
Q2O_LLM_SECONDARY=openai                  # Fallback if primary fails
Q2O_LLM_TERTIARY=anthropic                # Last resort

# Model Selection (per provider)
GEMINI_MODEL=gemini-1.5-pro              # or gemini-1.5-flash
OPENAI_MODEL=gpt-4-turbo                 # or gpt-4-0125-preview
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022  # or claude-3-opus

# ============================================================================
# GENERATION PARAMETERS
# ============================================================================

# Temperature (creativity vs determinism)
Q2O_LLM_TEMPERATURE=0.7                  # General tasks (0.0-1.0)
Q2O_LLM_CODE_TEMPERATURE=0.3             # Code generation (more deterministic)
Q2O_LLM_ANALYSIS_TEMPERATURE=0.5         # Code review/analysis

# Token Limits
Q2O_LLM_MAX_TOKENS=8192                  # Maximum output tokens
Q2O_LLM_MAX_INPUT_TOKENS=32000           # Maximum input tokens

# ============================================================================
# RETRY & FALLBACK CONFIGURATION
# ============================================================================

Q2O_LLM_MAX_RETRIES_PER_PROVIDER=3       # Retry each provider 3 times
Q2O_LLM_RETRY_DELAY_BASE=2               # Base delay in seconds (exponential backoff)
Q2O_LLM_FALLBACK_TO_TEMPLATE=true        # Use templates if all LLMs fail
Q2O_LLM_TIMEOUT_SECONDS=30               # API call timeout

# ============================================================================
# COST CONTROLS & BUDGET
# ============================================================================

# Monthly Budget (auto-allocates dynamically across agents)
Q2O_LLM_MONTHLY_BUDGET=1000.00           # Total monthly budget in USD

# Progressive Cost Alerts (7 levels)
Q2O_LLM_ALERT_50_PERCENT=true            # Alert at 50% ($500)
Q2O_LLM_ALERT_70_PERCENT=true            # Alert at 70% ($700)
Q2O_LLM_ALERT_80_PERCENT=true            # Alert at 80% ($800)
Q2O_LLM_ALERT_90_PERCENT=true            # Alert at 90% ($900)
Q2O_LLM_ALERT_95_PERCENT=true            # Alert at 95% ($950)
Q2O_LLM_ALERT_99_PERCENT=true            # Alert at 99% ($990)
Q2O_LLM_BUDGET_HARD_LIMIT=true           # Disable LLM at 100% (templates only)

# Daily Limits
Q2O_LLM_DAILY_CALL_LIMIT=1000            # Max LLM calls per day
Q2O_LLM_DAILY_COST_LIMIT=50.00           # Max daily spend in USD

# Alert Notification Channels
Q2O_LLM_ALERT_LOG=true                   # Log to console/file
Q2O_LLM_ALERT_DASHBOARD=true             # Show in Admin Dashboard
Q2O_LLM_ALERT_EMAIL=false                # Email notifications (configure SMTP)

# ============================================================================
# TEMPLATE LEARNING SYSTEM
# ============================================================================

Q2O_TEMPLATE_LEARNING_ENABLED=true       # Auto-learn from successful LLM generations
Q2O_TEMPLATE_MIN_QUALITY_TO_LEARN=90     # Only learn from 90%+ quality code
Q2O_TEMPLATE_PARAMETERIZATION=semi_auto  # manual | semi_auto | auto

# Template Learning Database
Q2O_LEARNED_TEMPLATES_DB=learned_templates.db
Q2O_TEMPLATE_MATCH_THRESHOLD=0.80        # 80% similarity to reuse template

# ============================================================================
# VALIDATION & QUALITY
# ============================================================================

Q2O_LLM_MIN_QUALITY_SCORE=95             # Minimum quality (0-100)
Q2O_LLM_CROSS_VALIDATION=true            # Use second LLM to validate critical code
Q2O_LLM_CROSS_VALIDATE_KEYWORDS=payment,auth,webhook,admin,sql,database

# Code Validation Checks
Q2O_VALIDATE_SYNTAX=true                 # Compile check
Q2O_VALIDATE_SECURITY=true               # Scan for dangerous patterns
Q2O_VALIDATE_TYPE_HINTS=true             # Require type hints
Q2O_VALIDATE_DOCSTRINGS=true             # Require docstrings
Q2O_VALIDATE_ERROR_HANDLING=true         # Require try/except

# ============================================================================
# CACHING
# ============================================================================

Q2O_LLM_CACHE_ENABLED=true               # Cache LLM responses
Q2O_LLM_CACHE_DIR=.llm_cache             # Cache directory
Q2O_LLM_CACHE_TTL_DAYS=90                # Cache time-to-live

# ============================================================================
# DEBUGGING & MONITORING
# ============================================================================

Q2O_LLM_DEBUG=false                      # Log all requests/responses (verbose)
Q2O_LLM_TRACK_USAGE=true                 # Track token usage and costs
Q2O_LLM_LOG_LEVEL=INFO                   # DEBUG | INFO | WARNING | ERROR
Q2O_LLM_DRY_RUN=false                    # Simulate LLM calls without API usage

# ============================================================================
# DASHBOARD INTEGRATION
# ============================================================================

Q2O_LLM_DASHBOARD_ENABLED=true           # Enable LLM Management in Admin Portal
Q2O_LLM_REALTIME_UPDATES=true            # Real-time cost updates via WebSocket

# ============================================================================
# FAILURE HANDLING
# ============================================================================

Q2O_LLM_GENERATE_FAILURE_REPORTS=true    # Generate detailed reports on total failure
Q2O_LLM_FAILURE_REPORT_DIR=failure_reports
Q2O_LLM_NOTIFY_ON_TOTAL_FAILURE=true     # Alert consultant when all methods fail

